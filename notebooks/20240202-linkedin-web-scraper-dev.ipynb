{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "Perform web scraping on the LinkedIn website. This is just for developing and testing the script. The web scraping script that is runnable via command line available in the src/scraper/linkedin_jobs_scraper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_element_handler(element):\n",
    "    if len(element) == 0:\n",
    "        return \"Not Found\"\n",
    "    else:\n",
    "        return element[0].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to run the script\n",
    "job_title = \"Data Scientist\"\n",
    "job_location = \"United States\"\n",
    "n_jobs = 25\n",
    "filepath = \"../data/raw/linkedin_jobs.csv\"\n",
    "\n",
    "# Open the LinkedIn\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to Jobs Page\n",
    "try:\n",
    "    page_num = 0\n",
    "    url = f\"https://www.linkedin.com/jobs/search/?keywords={job_title}&location={job_location}&start={page_num}\"\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Scroll the page until reach the certain amount of jobs to be scraped\n",
    "while True:\n",
    "    total_jobs = len(\n",
    "        driver.find_elements(By.CSS_SELECTOR, \"ul.jobs-search__results-list li\")\n",
    "    )\n",
    "\n",
    "    # Break loop uf reach certain amount\n",
    "    if total_jobs >= n_jobs:\n",
    "        break\n",
    "\n",
    "    # Perform scrolling activity\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "    try:\n",
    "        # Click if there's \"See more jobs\" button element\n",
    "        next = driver.find_element(\n",
    "            By.XPATH, \"//button[@aria-label='See more jobs']\"\n",
    "        )\n",
    "        next.click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Collect li element containing the jobs\n",
    "jobs = driver.find_elements(By.CSS_SELECTOR, \"ul.jobs-search__results-list li\")\n",
    "job_titles = []\n",
    "job_posts = []\n",
    "job_descriptions = []\n",
    "job_functions = []\n",
    "job_industries = []\n",
    "print(len(jobs))\n",
    "for i, job in enumerate(jobs):\n",
    "    try:\n",
    "        print(i, end=\"\\r\")\n",
    "        job.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        see_more_button = WebDriverWait(driver, 100).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    By.XPATH,\n",
    "                    '//button[@aria-label=\"Show more, visually expands previously read content above\"]',\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        see_more_button.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Get html elements\n",
    "        job_title_element = soup.select(\"h2.top-card-layout__title\")\n",
    "        job_post_element = soup.select(\"span.posted-time-ago__text\")\n",
    "        job_description_element = soup.select(\"div.show-more-less-html__markup\")\n",
    "        job_function_element = soup.select(\n",
    "            \"ul.description__job-criteria-list > li:nth-child(3) > span\"\n",
    "        )\n",
    "        job_industry_element = soup.select(\n",
    "            \"ul.description__job-criteria-list > li:nth-child(4) > span\"\n",
    "        )\n",
    "\n",
    "        # Extract content and append to the list\n",
    "        job_titles.append(html_element_handler(job_title_element))\n",
    "        job_posts.append(html_element_handler(job_post_element))\n",
    "        job_functions.append(html_element_handler(job_function_element))\n",
    "        job_industries.append(html_element_handler(job_industry_element))\n",
    "        job_description = re.sub(\n",
    "            \"<[^>]+>\", \" \", html_element_handler(job_description_element)\n",
    "        )\n",
    "        job_description = re.sub(\"[ ]+\", \" \", job_description)\n",
    "        job_descriptions.append(job_description)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"At iteration {i} with error of {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it in form of Pandas DataFrame\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"job_title\": job_titles,\n",
    "        \"job_post\": job_posts,\n",
    "        \"job_description\": job_descriptions,\n",
    "        \"job_function\": job_functions,\n",
    "        \"job_industry\": job_industries,\n",
    "    }\n",
    ").to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
