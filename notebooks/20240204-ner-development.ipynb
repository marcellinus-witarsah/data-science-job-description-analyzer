{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition Model\n",
    "In this python notebook, a NER model will be created by using the data scraped from LinkedIn jobs.\n",
    "The steps are:\n",
    "1. Data Cleaning\n",
    "2. Data Annotating\n",
    "3. Data Preparation\n",
    "4. Data Modelling\n",
    "5. Evaluation\n",
    "6. Predict on Test Data\n",
    "7. Visualize data using Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "sys.path.append(os.getenv(\"PROJECT_DIR\"))\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from tqdm import tqdm\n",
    "from src.data import DataLoader\n",
    "from src.data import DataPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "214it [00:03, 67.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = DataLoader.load_data(\"../data/raw/linkedin_jobs_train.csv\")\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Preprocess Job Descriptions\n",
    "texts = []\n",
    "data_preprocessor = DataPreprocessor(model_name=\"en_core_web_sm\")\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    texts.append(data_preprocessor.preprocess_job_desc(row['job_description'])+\"\\n\")\n",
    "\n",
    "# Save Jobs in form of jobs.txt\n",
    "with open(\"../data/interim/jobs_train.txt\", \"w\") as f:\n",
    "    f.writelines(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Annotating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate data using this link https://tecoholic.github.io/ner-annotator/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation \n",
    "\n",
    "Split data for train set, development set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Train and Dev\n",
    "# Open the annotations\n",
    "with open(\"../data/interim/annotations.json\", \"r\") as f:\n",
    "    annotations_json = json.load(f)\n",
    "\n",
    "# Set params for random select data\n",
    "total_size = len(annotations_json['annotations'])\n",
    "train_len, dev_len, test_len = int(total_size * 0.7), int(total_size * 0.15), int(total_size * 0.15) \n",
    "data = []\n",
    "for aj in annotations_json['annotations']:\n",
    "    data.append((aj[0], aj[1]))    \n",
    "\n",
    "# Randomized the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Prepare Train Data\n",
    "train_data = data[:train_len] \n",
    "db = DataPreprocessor.convert_to_doc_bin(train_data)\n",
    "db.to_disk(\"../data/processed/train.spacy\")\n",
    "\n",
    "# Prepare Dev Data\n",
    "dev_data = data[train_len : train_len + dev_len] \n",
    "db = DataPreprocessor.convert_to_doc_bin(dev_data)\n",
    "db.to_disk(\"../data/processed/dev.spacy\")\n",
    "\n",
    "# Prepare Test Data\n",
    "test_data = data[train_len + dev_len:] \n",
    "for data in test_data:\n",
    "    texts.append(data[0])\n",
    "\n",
    "with open(\"../data/interim/jobs_test.txt\", \"w\") as f:\n",
    "    f.writelines(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Modelling (From Scratch)\n",
    "Steps\n",
    "1. Download base configuration from spacy website according to NER modelling needs, create configuration for our training.\n",
    "2. Train the model using the configuration along with the train data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "!python -m spacy init fill-config ../config/base_config.cfg ../config/config.cfg\n",
    "# 2\n",
    "!python -m spacy train ../config/config.cfg --output ../models --paths.train ../data/processed/train.spacy --paths.dev ../data/processed/dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "Pick the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](../reports/figures/evaluation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Test Data\n",
    "with open(\"../data/interim/jobs_test.txt\", \"r\") as f:\n",
    "    test_data = f.readlines()\n",
    "\n",
    "# Access the Test Data and load Spacy Model\n",
    "best_model = spacy.load(\"../models/model-best\")\n",
    "i = 0\n",
    "hard_skills = []\n",
    "soft_skills = []\n",
    "for text in test_data:\n",
    "    docs = best_model(text)\n",
    "    for doc in docs.ents:\n",
    "        text = doc.text\n",
    "        text = re.sub(\" - \", \"-\", text)\n",
    "        text = re.sub(\" / \", \"/\", text)\n",
    "        text = re.sub(\" \", \"_\", text)\n",
    "        if doc.label_ == \"HARD SKILL\":\n",
    "            hard_skills.append(text)\n",
    "        elif doc.label_ == \"SOFT SKILL\":\n",
    "            text = re.sub(\"-\", \"_\", text)\n",
    "            soft_skills.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the list and lowercase all the words\n",
    "text = ' '.join(hard_skills).lower()\n",
    "\n",
    "#create the wordcloud object\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "#plot the wordcloud object\n",
    "plt.imshow(wordcloud, interpolation='bilInear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_skill_df = pd.DataFrame({\n",
    "    \"hard_skill\": hard_skills,\n",
    "})\n",
    "hard_skill_df['hard_skill'].value_counts().sort_values(ascending=True)[-30:].plot(kind=\"barh\", figsize=(10, 7), title=\"Top 30 Data Scientist Hard Skills\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the list and lowercase all the words\n",
    "text = ' '.join(soft_skills).lower()\n",
    "\n",
    "#create the wordcloud object\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "#plot the wordcloud object\n",
    "plt.imshow(wordcloud, interpolation='bilInear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_skill_df = pd.DataFrame({\n",
    "    \"soft_skill\": soft_skills,\n",
    "})\n",
    "soft_skill_df['soft_skill'].value_counts().sort_values(ascending=True)[-30:].plot(kind=\"barh\", figsize=(10, 7), title=\"Top 30 Data Scientist Soft Skills\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "hard_skill_df.to_csv(\"../reports/hard_skill.csv\", index=False)\n",
    "soft_skill_df.to_csv(\"../reports/soft_skill.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize in Tableau\n",
    "Link: https://public.tableau.com/views/DataScienceJobSkillsPlatform/Frontpage?:language=en-US&:display_count=n&:origin=viz_share_link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
